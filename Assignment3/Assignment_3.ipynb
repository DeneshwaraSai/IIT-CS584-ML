{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a39a74f-e60d-430d-a378-6e1948d1376f",
   "metadata": {},
   "source": [
    "## Assignment 3 (100 marks)\n",
    "#### =====================================================================================================\n",
    "### Deadline: 11/17 11:59 pm\n",
    "#### ====================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de21b2f3-2ca0-4730-aee8-50caf034dd6a",
   "metadata": {},
   "source": [
    "### Problem 1: PCA (20 marks)\n",
    "\n",
    "`lab03_dataset_1.csv` contains 205 observations on various vehicles. This is an unsupervised training data. You will use the entire dataset for the Principal Component Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7780c2-ba6a-4b91-9d85-deeed05ae60c",
   "metadata": {},
   "source": [
    "### 1.a (2 marks)\n",
    "For the 14 input features, drop any rows with missing numerical values and output the new length of the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f20e5b1-e8ba-4b32-bd45-3221b734acf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1dfcbb8-0c34-4a26-b85a-edc2f88aa9c9",
   "metadata": {},
   "source": [
    "### 1.b (2 marks)\n",
    "Normalize the dataset and generate the covariance matrix of the normalized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0668c4-46c5-4eef-8829-086dfefd3975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9e24135-9d2e-4c7f-ba29-92c43280a5b4",
   "metadata": {},
   "source": [
    "### 1.c (3 marks)\n",
    "Use `SVD` on the normalized dataset to obtain the 3 decomposed matrices and output them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a438d-a7a4-4861-b460-f8844ee3ac18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "697c2d6c-931f-4d29-ab4e-b1211633003d",
   "metadata": {},
   "source": [
    "### 1.d (3 marks)\n",
    "Generate the 3 largest eigenvalues from the decomposed matrices obtained from the `SVD`. Remember, eigenvalue $\\lambda=\\Lambda^2/n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de444d44-a6b5-412d-a4df-7b6d0142ba78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcb24605-56a0-4412-8b18-02c6316c268c",
   "metadata": {},
   "source": [
    "### 1.e (3 marks)\n",
    "Generate the projections of the normalized dataset using the first 3 principal components obtained from the `SVD` and display it inside a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3279235-f5af-47f1-919c-9c50f720fc78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f86e32c-26e9-4ee1-b624-67dd3e6e7540",
   "metadata": {},
   "source": [
    "### 1.f (3 marks)\n",
    "Use `eigen decomposition` on the covariance matrix to compute and output the eigenvalues and eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93210c0e-2be6-40e7-9bb8-6f91e340775f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a46e43d-9651-462b-b835-777a27c5bbf6",
   "metadata": {},
   "source": [
    "### 1.g (3 marks)\n",
    "Generate the projections of the normalized dataset using the first 3 principal components obtained from the `eigen decomposition` and display it inside a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c839bf4c-c302-403c-b59b-6db01b594061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "504877a5-a3de-4e23-955f-667bc80fde84",
   "metadata": {},
   "source": [
    "### 1.h (1 mark)\n",
    "Are the projections generated from 1.e and 1.g the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbc219f-ab33-44ed-a052-39ebc4f901c3",
   "metadata": {},
   "source": [
    " <font color='red'></font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f70b5d2-34d3-44f8-bfbf-d846c8f36c7f",
   "metadata": {},
   "source": [
    "### Problem 2: Clustering (20 marks)\n",
    "\n",
    "`lab03_dataset_2.csv` which contains 1440 observations with two input features `x1` and `x2`, generates 4 concentric rings. For this task, you will perform various clustering-related operations using the `sklearn clustering` module."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "891abda8-1b19-4511-8bc7-405b93bb06a2",
   "metadata": {},
   "source": [
    "### 2.a (5 marks)\n",
    "\n",
    "Apply `sklearn KMeans` on the two-dimensional data and output the resulting clusters using a scatterplot. You will apply `KMeans` over several clusters ranging from cluster-count `K = 2 to 6`. Make sure your scatterplot uses `K colors` to clearly distinguish the data points belonging in their respective `K clusters`. Also, compute the `Silhouette score` for each of those `K clusters` and plot the `Silhouette score` against `K clusters`. Label the plot axes accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3729365e-881c-4dc7-aeb5-b32887c32d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fa0f9a0-923c-43c8-b99f-057b2d61591d",
   "metadata": {},
   "source": [
    "### 2.b (5 marks)\n",
    "Repeat all the tasks in 2.a, but instead use `SpectralClustering`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa896947-e9e5-44ce-b4c1-59f9545a24f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "491340cf-5084-4ca8-babc-07ee594ef94b",
   "metadata": {},
   "source": [
    "### 2.c (5 marks)\n",
    "Repeat all the tasks in 2.a, but instead use `GaussianMixture`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52bcff-4c7a-4067-af29-1ae425cd9600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b7bf7b2-43f5-464b-80e3-2582c243a57b",
   "metadata": {},
   "source": [
    "### 2.d (5 marks)\n",
    "The dataset generates 4 concentric rings, so ideally we would want 4 clusters representing the 4 concentric rings. Did any of the clustering attempts in the above 3 tasks lead to 4 concentric ring clusters? Explore some other `sklearn clustering` algorithms to see which one can produce 4 clusters corresponding with the 4 concentric rings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf831e4a-cdef-4fa0-9c36-45ed38d4449e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "464a2f79-ef49-4fd7-a9f8-9e5dbaa29cde",
   "metadata": {},
   "source": [
    "### Problem 3: MLP Classification (20 marks)\n",
    "\n",
    "`lab03_dataset_3.csv` contains 103,904 observations on airlines customer reviews. For this classification task, use the `sklearn MLPClassifier` method, where the output class is the `Satisfaction` column which has a binary value of `Satisfied` or `Unsatisfied` and the remaining columns are the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b6121-d74e-4251-99a6-ccaf6afdcc2c",
   "metadata": {},
   "source": [
    "### 3.a (5 marks)\n",
    "Drop any rows with missing values and output the new length of the final training dataset. Transform the data after applying encoding to convert all categorical features into numerical values. Normalize the input features and apply a train-test split of 70-30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c42f2b-2ad9-4ee6-ab36-e4b2b30e1f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1c40696-c20f-4e78-98a6-a33d1dc6b177",
   "metadata": {},
   "source": [
    "### 3.b (5 marks)\n",
    "Build a `MLPClassifier` neural network with 3 hidden layers, with 10 neurons in each of those layers, and using the `ReLU` activation function. Output the `mean squared error` between the test cases and the neural network predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb7545c-9bff-48f6-ab7d-b5c07c7740e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "376759ea-05cf-4ca8-829e-cd69664ea2fe",
   "metadata": {},
   "source": [
    "### 3.c (5 marks)\n",
    "Repeat all the tasks in 3.b while using the `tanh` activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd058ec1-f01f-4bf9-a804-89c020d8f239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d70ecbb4-f421-48f1-b7e0-15bb5b6702e3",
   "metadata": {},
   "source": [
    "### 3.d (5 marks)\n",
    "Plot the training loss trajectory together for both the above neural network models generated using two different activation functions. Make sure to add legends and labels to your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda4af16-d41c-4fe8-a789-ddbb48baea51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f54755ba-c06d-40ae-b9dd-026989935edc",
   "metadata": {},
   "source": [
    "### Problem 4: MLP Prediction (40 marks)\n",
    "\n",
    "`lab03_dataset_4.csv` contains 973 observations on gym data. For this prediction task, use the `sklearn MLPRegressor` method, where the real-valued output feature is the `BMI` column and the remaining columns are the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d881dd4e-77c2-4b1d-b4cf-45b1e6f0d88f",
   "metadata": {},
   "source": [
    "### 4.a (5 marks)\n",
    "Transform the dataset after applying encoding to convert all categorical features into numerical values. Normalize the entire dataset (both the input and the output features) and apply a train-test split of 80-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eecc08-1da6-4675-9ee0-ba6048317c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d4335e8-0c63-421e-95d7-64285f3af3f6",
   "metadata": {},
   "source": [
    "### 4.b (5 marks)\n",
    "Build a `MLPRegressor` neural network with 3 hidden layers, with 10 neurons in each of those layers, and using the `tanh` activation function. Output the `mean squared error` between the test cases and the neural network predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe27bd8-3ab5-429d-a951-fcf2151934e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc92107f-9728-4d02-ad8b-788020271218",
   "metadata": {},
   "source": [
    "### 4.c (5 marks)\n",
    "Repeat all the tasks in 4.b while using the `sigmoid` activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49ed66-fde9-463f-a8fc-f2901c34915d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8a6b573-aecb-497b-874f-2531e7eaaf72",
   "metadata": {},
   "source": [
    "### 4.d (5 marks)\n",
    "Plot the training loss trajectory together for both the above neural network models generated using two different activation functions. Make sure to add legends and labels to your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb13ada-76f1-43ad-9f37-933fd5778fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "252ee855-7f6d-4d2f-89d1-ea8f411a0c90",
   "metadata": {},
   "source": [
    "### 4.e (6 marks)\n",
    "Using the `sklearn PCA` method, compute all the principal components (PCs) of the normalized dataset. All the PCs capture a fraction of the total variance, output all the variances captured by all the PCs. Write a code snippet that checks all the PCs and selects the `top k PCs` whose total variance captured is more than `70%`. What did `k` come out to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff6365-e440-421e-985d-d206dbeb2840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cb4747a-6afb-4284-99d3-7c8f73ed794d",
   "metadata": {},
   "source": [
    "### 4.f (3 marks)\n",
    "Using the `top k PCs`, apply `dimensionality reduction` on the normalized dataset to generate the transformed dataset which should now have only `k columns`. This newly transformed dataset is the new input features which will be used for training. Continue using the same normalized output feature column. Generate a train-test split of 80-20 from this new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e8b70-1d51-4a18-84d4-8f9fb1b5d5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76fbc001-58c4-4754-b203-4cb57d7b880d",
   "metadata": {},
   "source": [
    "### 4.g (6 marks)\n",
    "Using the newly obtained transformed dataset, redo tasks 4.b and 4.c to obtain the `mean squared error` for both the neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a5c7a-1b98-4d51-aa3d-7531ff3546f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0004d59-8398-4844-be35-813dc7040604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b84b106b-52f8-4aae-a4aa-dd590fca4339",
   "metadata": {},
   "source": [
    "### 4.h (5 marks)\n",
    "Repeat task 4.d to plot the training loss trajectory for both the neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b87d9-7817-4416-9263-614f7d9cd45e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
